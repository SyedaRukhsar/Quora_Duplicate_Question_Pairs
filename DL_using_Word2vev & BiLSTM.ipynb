{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13110804,"sourceType":"datasetVersion","datasetId":8305151}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Required Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom bs4 import BeautifulSoup\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:45:16.097566Z","iopub.execute_input":"2025-09-23T14:45:16.098083Z","iopub.status.idle":"2025-09-23T14:45:16.101736Z","shell.execute_reply.started":"2025-09-23T14:45:16.098061Z","shell.execute_reply":"2025-09-23T14:45:16.101038Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/quora-duplicate-questions-dataset/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:45:16.149818Z","iopub.execute_input":"2025-09-23T14:45:16.150283Z","iopub.status.idle":"2025-09-23T14:45:17.234425Z","shell.execute_reply.started":"2025-09-23T14:45:16.150266Z","shell.execute_reply":"2025-09-23T14:45:17.233515Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:45:17.235777Z","iopub.execute_input":"2025-09-23T14:45:17.236055Z","iopub.status.idle":"2025-09-23T14:45:17.240951Z","shell.execute_reply.started":"2025-09-23T14:45:17.236033Z","shell.execute_reply":"2025-09-23T14:45:17.240201Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"(404290, 6)"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:45:17.241677Z","iopub.execute_input":"2025-09-23T14:45:17.241916Z","iopub.status.idle":"2025-09-23T14:45:17.260952Z","shell.execute_reply.started":"2025-09-23T14:45:17.241900Z","shell.execute_reply":"2025-09-23T14:45:17.260371Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"   id  qid1  qid2                                          question1  \\\n0   0     1     2  What is the step by step guide to invest in sh...   \n1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2   2     5     6  How can I increase the speed of my internet co...   \n3   3     7     8  Why am I mentally very lonely? How can I solve...   \n4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  \n0  What is the step by step guide to invest in sh...             0  \n1  What would happen if the Indian government sto...             0  \n2  How can Internet speed be increased by hacking...             0  \n3  Find the remainder when [math]23^{24}[/math] i...             0  \n4            Which fish would survive in salt water?             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Random Sampling of 400k Rows from Dataset","metadata":{}},{"cell_type":"code","source":"new_df = df.sample(400000,random_state = 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:45:17.262611Z","iopub.execute_input":"2025-09-23T14:45:17.262810Z","iopub.status.idle":"2025-09-23T14:45:17.402522Z","shell.execute_reply.started":"2025-09-23T14:45:17.262795Z","shell.execute_reply":"2025-09-23T14:45:17.401942Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"dataset = new_df[['question1', 'question2', 'is_duplicate']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:45:17.403154Z","iopub.execute_input":"2025-09-23T14:45:17.403330Z","iopub.status.idle":"2025-09-23T14:45:17.427332Z","shell.execute_reply.started":"2025-09-23T14:45:17.403314Z","shell.execute_reply":"2025-09-23T14:45:17.426792Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"print(dataset.shape)\ndataset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:45:17.428013Z","iopub.execute_input":"2025-09-23T14:45:17.428256Z","iopub.status.idle":"2025-09-23T14:45:17.436157Z","shell.execute_reply.started":"2025-09-23T14:45:17.428235Z","shell.execute_reply":"2025-09-23T14:45:17.435423Z"}},"outputs":[{"name":"stdout","text":"(400000, 3)\n","output_type":"stream"},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"                                                question1  \\\n398782  What is the best marketing automation tool for...   \n115086  I am poor but I want to invest. What should I do?   \n327711  I am from India and live abroad. I met a guy f...   \n367788  Why do so many people in the U.S. hate the sou...   \n151235                Consequences of Bhopal gas tragedy?   \n\n                                                question2  is_duplicate  \n398782  What is the best marketing automation tool for...             1  \n115086  I am quite poor and I want to be very rich. Wh...             0  \n327711  T.I.E.T to Thapar University to Thapar Univers...             0  \n367788  My boyfriend doesnt feel guilty when he hurts ...             0  \n151235  What was the reason behind the Bhopal gas trag...             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>398782</th>\n      <td>What is the best marketing automation tool for...</td>\n      <td>What is the best marketing automation tool for...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>115086</th>\n      <td>I am poor but I want to invest. What should I do?</td>\n      <td>I am quite poor and I want to be very rich. Wh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>327711</th>\n      <td>I am from India and live abroad. I met a guy f...</td>\n      <td>T.I.E.T to Thapar University to Thapar Univers...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>367788</th>\n      <td>Why do so many people in the U.S. hate the sou...</td>\n      <td>My boyfriend doesnt feel guilty when he hurts ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>151235</th>\n      <td>Consequences of Bhopal gas tragedy?</td>\n      <td>What was the reason behind the Bhopal gas trag...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":64},{"cell_type":"markdown","source":"# Text Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess(q):\n    q = str(q).lower().strip()\n\n#Replace certain special characters with their equivalents\n    q = q.replace('%','percent')\n    q = q.replace('$','dollar')\n    q = q.replace('@','at')\n    q = q.replace('₹', 'rupee')\n    q = q.replace('€', 'euro')\n\n# the pattern '[math]' appears around 900 times in the whole dataset.\n    q = q.replace('[math]','')\n\n# replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)\n    q = q.replace(',000,000,000','b')\n    q = q.replace(',000,000','m')\n    q = q.replace(',000','k')\n    q = re.sub(r'([0-9]+)000000000',r'\\1b',q)\n    q = re.sub(r'([0-9]+)000000',r'\\1m',q)\n    q = re.sub(r'([0-9]+)000',r'\\1k',q)\n\n\n# Decontracting Words\n#https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/19794953?newreg=c7cc89d538bf4ff5864e477a0a7e2442\n\n    contractions = { \n    \"ain't\": \"am not / are not / is not / has not / have not\",\n    \"aren't\": \"are not / am not\",\n    \"can't\": \"cannot\",\n    \"can't've\": \"cannot have\",\n    \"'cause\": \"because\",\n    \"could've\": \"could have\",\n    \"couldn't\": \"could not\",\n    \"couldn't've\": \"could not have\",\n    \"didn't\": \"did not\",\n    \"doesn't\": \"does not\",\n    \"don't\": \"do not\",\n    \"hadn't\": \"had not\",\n    \"hadn't've\": \"had not have\",\n    \"hasn't\": \"has not\",\n    \"haven't\": \"have not\",\n    \"he'd\": \"he had / he would\",\n    \"he'd've\": \"he would have\",\n    \"he'll\": \"he shall / he will\",\n    \"he'll've\": \"he shall have / he will have\",\n    \"he's\": \"he has / he is\",\n    \"how'd\": \"how did\",\n    \"how'd'y\": \"how do you\",\n    \"how'll\": \"how will\",\n    \"how's\": \"how has / how is / how does\",\n    \"I'd\": \"I had / I would\",\n    \"I'd've\": \"I would have\",\n    \"I'll\": \"I shall / I will\",\n    \"I'll've\": \"I shall have / I will have\",\n    \"I'm\": \"I am\",\n    \"I've\": \"I have\",\n    \"isn't\": \"is not\",\n    \"it'd\": \"it had / it would\",\n    \"it'd've\": \"it would have\",\n    \"it'll\": \"it shall / it will\",\n    \"it'll've\": \"it shall have / it will have\",\n    \"it's\": \"it has / it is\",\n    \"let's\": \"let us\",\n    \"ma'am\": \"madam\",\n    \"mayn't\": \"may not\",\n    \"might've\": \"might have\",\n    \"mightn't\": \"might not\",\n    \"mightn't've\": \"might not have\",\n    \"must've\": \"must have\",\n    \"mustn't\": \"must not\",\n    \"mustn't've\": \"must not have\",\n    \"needn't\": \"need not\",\n    \"needn't've\": \"need not have\",\n    \"o'clock\": \"of the clock\",\n    \"oughtn't\": \"ought not\",\n    \"oughtn't've\": \"ought not have\",\n    \"shan't\": \"shall not\",\n    \"sha'n't\": \"shall not\",\n    \"shan't've\": \"shall not have\",\n    \"she'd\": \"she had / she would\",\n    \"she'd've\": \"she would have\",\n    \"she'll\": \"she shall / she will\",\n    \"she'll've\": \"she shall have / she will have\",\n    \"she's\": \"she has / she is\",\n    \"should've\": \"should have\",\n    \"shouldn't\": \"should not\",\n    \"shouldn't've\": \"should not have\",\n    \"so've\": \"so have\",\n    \"so's\": \"so as / so is\",\n    \"that'd\": \"that would / that had\",\n    \"that'd've\": \"that would have\",\n    \"that's\": \"that has / that is\",\n    \"there'd\": \"there had / there would\",\n    \"there'd've\": \"there would have\",\n    \"there's\": \"there has / there is\",\n    \"they'd\": \"they had / they would\",\n    \"they'd've\": \"they would have\",\n    \"they'll\": \"they shall / they will\",\n    \"they'll've\": \"they shall have / they will have\",\n    \"they're\": \"they are\",\n    \"they've\": \"they have\",\n    \"to've\": \"to have\",\n    \"wasn't\": \"was not\",\n    \"we'd\": \"we had / we would\",\n    \"we'd've\": \"we would have\",\n    \"we'll\": \"we will\",\n    \"we'll've\": \"we will have\",\n    \"we're\": \"we are\",\n    \"we've\": \"we have\",\n    \"weren't\": \"were not\",\n    \"what'll\": \"what shall / what will\",\n    \"what'll've\": \"what shall have / what will have\",\n    \"what're\": \"what are\",\n    \"what's\": \"what has / what is\",\n    \"what've\": \"what have\",\n    \"when's\": \"when has / when is\",\n    \"when've\": \"when have\",\n    \"where'd\": \"where did\",\n    \"where's\": \"where has / where is\",\n    \"where've\": \"where have\",\n    \"who'll\": \"who shall / who will\",\n    \"who'll've\": \"who shall have / who will have\",\n    \"who's\": \"who has / who is\",\n    \"who've\": \"who have\",\n    \"why's\": \"why has / why is\",\n    \"why've\": \"why have\",\n    \"will've\": \"will have\",\n    \"won't\": \"will not\",\n    \"won't've\": \"will not have\",\n    \"would've\": \"would have\",\n    \"wouldn't\": \"would not\",\n    \"wouldn't've\": \"would not have\",\n    \"y'all\": \"you all\",\n    \"y'all'd\": \"you all would\",\n    \"y'all'd've\": \"you all would have\",\n    \"y'all're\": \"you all are\",\n    \"y'all've\": \"you all have\",\n    \"you'd\": \"you had / you would\",\n    \"you'd've\": \"you would have\",\n    \"you'll\": \"you shall / you will\",\n    \"you'll've\": \"you shall have / you will have\",\n    \"you're\": \"you are\",\n    \"you've\": \"you have\"\n    }\n\n    q_decontracted = []\n    for word in q.split():\n        if word in contractions:\n            word = contractions[word]\n        q_decontracted.append(word)\n\n    q = \" \".join(q_decontracted)\n    q = q.replace(\"'ve\",\" have\")\n    q = q.replace(\"n't\",\" not\")\n    q = q.replace(\"'re\",\" are\")\n    q = q.replace(\"'ll\",\" will\")\n    # removing html tags\n\n    q = BeautifulSoup(q)\n    q = q.get_text()\n\n    # Remove punctuation\n    pattern = re.compile('\\W')\n    q = re.sub(pattern,' ',q).strip()\n\n    return q\n\n    \n    \n\n\n   \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:45:17.436887Z","iopub.execute_input":"2025-09-23T14:45:17.437052Z","iopub.status.idle":"2025-09-23T14:45:17.452018Z","shell.execute_reply.started":"2025-09-23T14:45:17.437038Z","shell.execute_reply":"2025-09-23T14:45:17.451244Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"preprocess(\"I've already! wasn't  <b>done</b>?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:45:17.452762Z","iopub.execute_input":"2025-09-23T14:45:17.452998Z","iopub.status.idle":"2025-09-23T14:45:17.475536Z","shell.execute_reply.started":"2025-09-23T14:45:17.452976Z","shell.execute_reply":"2025-09-23T14:45:17.474798Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"'i have already  was not done'"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"dataset['question1'] = dataset['question1'].apply(preprocess)\ndataset['question2'] = dataset['question2'].apply(preprocess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:45:17.476379Z","iopub.execute_input":"2025-09-23T14:45:17.476655Z","iopub.status.idle":"2025-09-23T14:47:36.796238Z","shell.execute_reply.started":"2025-09-23T14:45:17.476632Z","shell.execute_reply":"2025-09-23T14:47:36.795389Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:47:36.798997Z","iopub.execute_input":"2025-09-23T14:47:36.799213Z","iopub.status.idle":"2025-09-23T14:47:36.806730Z","shell.execute_reply.started":"2025-09-23T14:47:36.799196Z","shell.execute_reply":"2025-09-23T14:47:36.806117Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"                                                question1  \\\n398782  what is the best marketing automation tool for...   \n115086   i am poor but i want to invest  what should i do   \n327711  i am from india and live abroad  i met a guy f...   \n367788  why do so many people in the u s  hate the sou...   \n151235                 consequences of bhopal gas tragedy   \n\n                                                question2  is_duplicate  \n398782  what is the best marketing automation tool for...             1  \n115086  i am quite poor and i want to be very rich  wh...             0  \n327711  t i e t to thapar university to thapar univers...             0  \n367788  my boyfriend doesnt feel guilty when he hurts ...             0  \n151235  what was the reason behind the bhopal gas tragedy             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>398782</th>\n      <td>what is the best marketing automation tool for...</td>\n      <td>what is the best marketing automation tool for...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>115086</th>\n      <td>i am poor but i want to invest  what should i do</td>\n      <td>i am quite poor and i want to be very rich  wh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>327711</th>\n      <td>i am from india and live abroad  i met a guy f...</td>\n      <td>t i e t to thapar university to thapar univers...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>367788</th>\n      <td>why do so many people in the u s  hate the sou...</td>\n      <td>my boyfriend doesnt feel guilty when he hurts ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>151235</th>\n      <td>consequences of bhopal gas tragedy</td>\n      <td>what was the reason behind the bhopal gas tragedy</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":68},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:47:36.807339Z","iopub.execute_input":"2025-09-23T14:47:36.807615Z","iopub.status.idle":"2025-09-23T14:47:36.826340Z","shell.execute_reply.started":"2025-09-23T14:47:36.807588Z","shell.execute_reply":"2025-09-23T14:47:36.825831Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"tokenizer = Tokenizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:47:36.826979Z","iopub.execute_input":"2025-09-23T14:47:36.827184Z","iopub.status.idle":"2025-09-23T14:47:36.853635Z","shell.execute_reply.started":"2025-09-23T14:47:36.827160Z","shell.execute_reply":"2025-09-23T14:47:36.852949Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:47:36.854353Z","iopub.execute_input":"2025-09-23T14:47:36.854888Z","iopub.status.idle":"2025-09-23T14:47:36.871598Z","shell.execute_reply.started":"2025-09-23T14:47:36.854864Z","shell.execute_reply":"2025-09-23T14:47:36.871010Z"}},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"                                                question1  \\\n398782  what is the best marketing automation tool for...   \n115086   i am poor but i want to invest  what should i do   \n327711  i am from india and live abroad  i met a guy f...   \n367788  why do so many people in the u s  hate the sou...   \n151235                 consequences of bhopal gas tragedy   \n\n                                                question2  is_duplicate  \n398782  what is the best marketing automation tool for...             1  \n115086  i am quite poor and i want to be very rich  wh...             0  \n327711  t i e t to thapar university to thapar univers...             0  \n367788  my boyfriend doesnt feel guilty when he hurts ...             0  \n151235  what was the reason behind the bhopal gas tragedy             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>398782</th>\n      <td>what is the best marketing automation tool for...</td>\n      <td>what is the best marketing automation tool for...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>115086</th>\n      <td>i am poor but i want to invest  what should i do</td>\n      <td>i am quite poor and i want to be very rich  wh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>327711</th>\n      <td>i am from india and live abroad  i met a guy f...</td>\n      <td>t i e t to thapar university to thapar univers...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>367788</th>\n      <td>why do so many people in the u s  hate the sou...</td>\n      <td>my boyfriend doesnt feel guilty when he hurts ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>151235</th>\n      <td>consequences of bhopal gas tragedy</td>\n      <td>what was the reason behind the bhopal gas tragedy</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":71},{"cell_type":"markdown","source":"# Tokenization & Padding of Question Pairs","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\n# Step 1: Tokenizer fit on combined text of both question1 and question2\ntokenizer.fit_on_texts(pd.concat([dataset['question1'], dataset['question2']]))\n\n# Convert question1 and question2 into sequences of integers\nq1_sequences = tokenizer.texts_to_sequences(dataset['question1'])\nq2_sequences = tokenizer.texts_to_sequences(dataset['question2'])\n\n# Step 2: Find maximum sequence length across both Q1 and Q2\nmax_len = max(max(map(len, q1_sequences)), max(map(len, q2_sequences)))\n\n# Step 3: Pad all sequences to the same length (post-padding with zeros)\nq1_padded = pad_sequences(q1_sequences, maxlen=max_len, padding='post')\nq2_padded = pad_sequences(q2_sequences, maxlen=max_len, padding='post')\n\n# Shapes after padding\nprint(\"Q1 shape:\", q1_padded.shape)\nprint(\"Q2 shape:\", q2_padded.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:47:36.872361Z","iopub.execute_input":"2025-09-23T14:47:36.872608Z","iopub.status.idle":"2025-09-23T14:47:56.404587Z","shell.execute_reply.started":"2025-09-23T14:47:36.872586Z","shell.execute_reply":"2025-09-23T14:47:56.403944Z"}},"outputs":[{"name":"stdout","text":"Q1 shape: (400000, 253)\nQ2 shape: (400000, 253)\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"# Combine question1 and question2 padded sequences\nX = np.concatenate([q1_padded, q2_padded], axis=1)\n\n# Train-test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, dataset['is_duplicate'], test_size=0.1, random_state=42)\n\n# Convert to numpy with correct dtypes\nX_train = np.array(X_train).astype(np.int32)\nX_test = np.array(X_test).astype(np.int32)\ny_train = np.array(y_train).astype(np.float32)\ny_test = np.array(y_test).astype(np.float32)\n\nprint(\"X_train shape:\", X_train.shape)\nprint(\"y_train shape:\", y_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:47:56.441829Z","iopub.execute_input":"2025-09-23T14:47:56.442096Z","iopub.status.idle":"2025-09-23T14:47:57.600421Z","shell.execute_reply.started":"2025-09-23T14:47:56.442082Z","shell.execute_reply":"2025-09-23T14:47:57.599779Z"}},"outputs":[{"name":"stdout","text":"X_train shape: (360000, 506)\ny_train shape: (360000,)\n","output_type":"stream"}],"execution_count":76},{"cell_type":"markdown","source":"# Training Word2Vec Embeddings for Quora Question Pairs","metadata":{}},{"cell_type":"code","source":"from gensim.models import Word2Vec\nfrom tensorflow.keras.preprocessing.text import text_to_word_sequence\nimport multiprocessing\n\n# Training Word2Vec Embeddings for Quora Question Pairs\n\n# Prepare corpus by combining 'question1' and 'question2' columns into a single list\n# This ensures that the Word2Vec model learns word relationships across both fields\nquestions = pd.concat([dataset['question1'].astype(str), dataset['question2'].astype(str)], axis=0).tolist()\n\n# Tokenize each question into a list of words (lowercased + punctuation removed)\n# Example: \"How are you?\" -> [\"how\", \"are\", \"you\"]\ntokenized_sentences = [text_to_word_sequence(q) for q in questions]\n\n# Initialize and train Word2Vec model\n# - vector_size: dimensionality of embeddings (common choices: 100 or 300)\n# - window: context window size (number of words before/after target word)\n# - min_count: ignore words with frequency < 2 (reduces noise)\n# - workers: number of CPU cores used for training (parallelization)\n# - sg: training algorithm (1 = Skip-gram, 0 = CBOW)\n# - epochs: number of training iterations over the data\nembedding_dim = 300\nw2v_model = Word2Vec(\n    sentences=tokenized_sentences,\n    vector_size=embedding_dim,\n    window=5,\n    min_count=2,\n    workers=multiprocessing.cpu_count(),\n    sg=1,   # Skip-gram model is better for capturing semantic meaning\n    epochs=5\n)\n\n# Print confirmation and size of the learned vocabulary\nprint(\"Word2Vec training done. Vocabulary size:\", len(w2v_model.wv))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:47:57.601180Z","iopub.execute_input":"2025-09-23T14:47:57.601433Z","iopub.status.idle":"2025-09-23T14:49:50.683735Z","shell.execute_reply.started":"2025-09-23T14:47:57.601413Z","shell.execute_reply":"2025-09-23T14:49:50.683053Z"}},"outputs":[{"name":"stdout","text":"Word2Vec training done. Vocabulary size: 52405\n","output_type":"stream"}],"execution_count":77},{"cell_type":"markdown","source":"# Creating Embedding Matrix from Word2Vec for LSTM/ML Models","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Total vocabulary size (all unique tokens from tokenizer)\n# +1 is added for padding token (index 0, usually reserved)\nvocab_size = len(tokenizer.word_index) + 1  \n\n# Initialize embedding matrix with zeros\n# Shape: (vocab_size, embedding_dim)\n# Each row represents the embedding vector for one word\nembedding_matrix = np.zeros((vocab_size, embedding_dim))\n\n# Track how many words are Out-Of-Vocabulary (OOV) i.e., not found in trained Word2Vec\noov_count = 0\n\n# Fill embedding matrix\nfor word, i in tokenizer.word_index.items():\n    if word in w2v_model.wv:\n        # If the word exists in Word2Vec vocabulary, use its trained embedding\n        embedding_matrix[i] = w2v_model.wv[word]\n    else:\n        # If not found (OOV), initialize a random vector\n        # Random initialization helps model learn embeddings during training\n        embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim, ))  \n        oov_count += 1  # count OOV words\n\n# Display embedding matrix details\nprint(\"Embedding matrix shape:\", embedding_matrix.shape)   # Should be (vocab_size, embedding_dim)\nprint(\"Out of vocab words:\", oov_count)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:49:50.684430Z","iopub.execute_input":"2025-09-23T14:49:50.684649Z","iopub.status.idle":"2025-09-23T14:49:51.379368Z","shell.execute_reply.started":"2025-09-23T14:49:50.684632Z","shell.execute_reply":"2025-09-23T14:49:51.378613Z"}},"outputs":[{"name":"stdout","text":"Embedding matrix shape: (86383, 300)\nOut of vocab words: 33977\n","output_type":"stream"}],"execution_count":78},{"cell_type":"markdown","source":"# BiLSTM Model for Quora Duplicate Question Pairs","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n\n# -------------------------------\n# BiLSTM Model for Quora Duplicate Question Pairs\n# -------------------------------\n\n# max_len = length of padded sequences (combined q1 + q2 tokens)\n# This defines the fixed input size for the model\nmax_len = X_train.shape[1]  \n\n# Initialize Sequential model\nmodel = Sequential()\n\n# Embedding layer (using pre-trained Word2Vec embeddings)\nmodel.add(Embedding(\n    input_dim=vocab_size,          # total vocabulary size\n    output_dim=embedding_dim,      # embedding dimension (e.g., 300)\n    weights=[embedding_matrix],    # pre-trained embedding matrix\n    input_length=max_len,          # input length = max padded sequence length\n    trainable=True                 # embeddings will be fine-tuned during training\n))\n\n# First Bidirectional LSTM layer\n# return_sequences=True → passes full sequence to next LSTM\nmodel.add(Bidirectional(LSTM(256, return_sequences=True)))\n\n# Dropout to prevent overfitting\nmodel.add(Dropout(0.3))\n\n# Second Bidirectional LSTM layer\n# No return_sequences → outputs final hidden state only\nmodel.add(Bidirectional(LSTM(256)))\n\n# Dense layer with ReLU activation (hidden layer for learning complex patterns)\nmodel.add(Dense(256, activation='relu'))\n\n# Dropout again for regularization\nmodel.add(Dropout(0.4))\n\n# Output layer → 1 neuron (binary classification: duplicate or not)\n# Sigmoid activation gives probability between 0 and 1\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(\n    loss='binary_crossentropy',    # suitable for binary classification\n    optimizer='adam',              # adaptive optimizer\n    metrics=['accuracy']           # track accuracy\n)\n\n# Print model summary to check architecture\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:49:51.384811Z","iopub.execute_input":"2025-09-23T14:49:51.385059Z","iopub.status.idle":"2025-09-23T14:49:51.687638Z","shell.execute_reply.started":"2025-09-23T14:49:51.385040Z","shell.execute_reply":"2025-09-23T14:49:51.687078Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │    \u001b[38;5;34m25,914,900\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,914,900</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,914,900\u001b[0m (98.86 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,914,900</span> (98.86 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,914,900\u001b[0m (98.86 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,914,900</span> (98.86 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":80},{"cell_type":"markdown","source":"# Training BiLSTM with EarlyStopping & ModelCheckpoint","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# EarlyStopping → stop training when validation loss stops improving\nes = EarlyStopping(\n    monitor='val_loss',        # monitor validation loss\n    patience=3,                # stop if no improvement for 3 epochs\n    restore_best_weights=True  # restore weights from the best epoch\n)\n\n# ModelCheckpoint → save best model based on validation accuracy\nmc = ModelCheckpoint(\n    'best_model.h5',           # filename to save best model\n    monitor='val_accuracy',    # monitor validation accuracy\n    save_best_only=True,       # save only the best model\n    mode='max'                 # maximize validation accuracy\n)\n\n# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    epochs=10,                 # number of training epochs\n    batch_size=512,            # number of samples per batch\n    validation_split=0.1,      # 10% of training data used for validation\n    callbacks=[es, mc],        # use EarlyStopping & ModelCheckpoint\n    verbose=1                  # 1 = progress bar with details\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:49:51.692567Z","iopub.execute_input":"2025-09-23T14:49:51.693083Z","iopub.status.idle":"2025-09-23T16:15:42.467694Z","shell.execute_reply.started":"2025-09-23T14:49:51.693061Z","shell.execute_reply":"2025-09-23T16:15:42.466584Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1041s\u001b[0m 2s/step - accuracy: 0.7159 - loss: 0.5558 - val_accuracy: 0.7515 - val_loss: 0.5031\nEpoch 2/10\n\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1028s\u001b[0m 2s/step - accuracy: 0.7671 - loss: 0.4777 - val_accuracy: 0.7566 - val_loss: 0.4973\nEpoch 3/10\n\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1027s\u001b[0m 2s/step - accuracy: 0.7968 - loss: 0.4198 - val_accuracy: 0.7632 - val_loss: 0.5110\nEpoch 4/10\n\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1028s\u001b[0m 2s/step - accuracy: 0.8239 - loss: 0.3682 - val_accuracy: 0.7674 - val_loss: 0.5520\nEpoch 5/10\n\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1025s\u001b[0m 2s/step - accuracy: 0.8451 - loss: 0.3271 - val_accuracy: 0.7586 - val_loss: 0.6299\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"# Load best saved model\nfrom tensorflow.keras.models import load_model\nbest_model = load_model('best_model.h5')\n\n# Evaluate on test set\nloss, acc = best_model.evaluate(X_test, y_test, verbose=1)\nprint(f\"Test Accuracy: {acc*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T16:15:42.469453Z","iopub.execute_input":"2025-09-23T16:15:42.469794Z","iopub.status.idle":"2025-09-23T16:16:58.900257Z","shell.execute_reply.started":"2025-09-23T16:15:42.469764Z","shell.execute_reply":"2025-09-23T16:16:58.899704Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 59ms/step - accuracy: 0.7726 - loss: 0.5419\nTest Accuracy: 77.05%\n","output_type":"stream"}],"execution_count":83}]}