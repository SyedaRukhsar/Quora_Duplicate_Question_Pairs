{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Required Libraries"
      ],
      "metadata": {
        "id": "ZaOIi7Jd-fx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic imports\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "\n",
        "# TensorFlow / Keras imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, BatchNormalization, Lambda, concatenate, Multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYlQLAi3XbTk",
        "outputId": "165f0374-6f24-4147-fe4d-2a84d3a7db48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# select columns first\n",
        "df = df[['question1', 'question2', 'is_duplicate']]\n",
        "\n",
        "# then drop missing values (inplace)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# convert label to int\n",
        "df['is_duplicate'] = df['is_duplicate'].astype(int)\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(df['is_duplicate'].value_counts(normalize=True))\n",
        "print(df.head(3).to_dict(orient='records'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1eYe8UZXbZi",
        "outputId": "870b0ad0-c8d2-4613-d6d2-28c821515cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (404287, 3)\n",
            "is_duplicate\n",
            "0    0.630799\n",
            "1    0.369201\n",
            "Name: proportion, dtype: float64\n",
            "[{'question1': 'What is the step by step guide to invest in share market in india?', 'question2': 'What is the step by step guide to invest in share market?', 'is_duplicate': 0}, {'question1': 'What is the story of Kohinoor (Koh-i-Noor) Diamond?', 'question2': 'What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?', 'is_duplicate': 0}, {'question1': 'How can I increase the speed of my internet connection while using a VPN?', 'question2': 'How can Internet speed be increased by hacking through DNS?', 'is_duplicate': 0}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "rhyKVuDf-xN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "def preprocess(q):\n",
        "    q = str(q).lower().strip()\n",
        "\n",
        "    # Replace special characters\n",
        "    q = q.replace('%','percent').replace('$','dollar').replace('@','at').replace('₹','rupee').replace('€','euro')\n",
        "\n",
        "    # Remove math token\n",
        "    q = q.replace('[math]','')\n",
        "\n",
        "    # Numbers to k/m/b\n",
        "    q = q.replace(',000,000,000','b').replace(',000,000','m').replace(',000','k')\n",
        "    q = re.sub(r'([0-9]+)000000000',r'\\1b',q)\n",
        "    q = re.sub(r'([0-9]+)000000',r'\\1m',q)\n",
        "    q = re.sub(r'([0-9]+)000',r'\\1k',q)\n",
        "\n",
        "    # Contractions\n",
        "    contractions = {\n",
        "       \"ain't\":\"is not\",\"aren't\":\"are not\",\"can't\":\"cannot\",\"can't've\":\"cannot have\",\"cause\":\"because\",\n",
        "    \"could've\":\"could have\",\"couldn't\":\"could not\",\"didn't\":\"did not\",\"doesn't\":\"does not\",\"don't\":\"do not\",\n",
        "    \"hadn't\":\"had not\",\"hasn't\":\"has not\",\"haven't\":\"have not\",\"he'd\":\"he would\",\"he'll\":\"he will\",\n",
        "    \"he's\":\"he is\",\"how'd\":\"how did\",\"how'll\":\"how will\",\"how's\":\"how is\",\"i'd\":\"i would\",\"i'll\":\"i will\",\n",
        "    \"i'm\":\"i am\",\"isn't\":\"is not\",\"it'd\":\"it would\",\"it'll\":\"it will\",\"it's\":\"it is\",\"let's\":\"let us\",\n",
        "    \"ma'am\":\"madam\",\"mightn't\":\"might not\",\"mustn't\":\"must not\",\"shan't\":\"shall not\",\"she'd\":\"she would\",\n",
        "    \"she'll\":\"she will\",\"she's\":\"she is\",\"should've\":\"should have\",\"shouldn't\":\"should not\",\"that's\":\"that is\",\n",
        "    \"there's\":\"there is\",\"they'd\":\"they would\",\"they'll\":\"they will\",\"they're\":\"they are\",\"they've\":\"they have\",\n",
        "    \"wasn't\":\"was not\",\"we'd\":\"we would\",\"we're\":\"we are\",\"we've\":\"we have\",\"weren't\":\"were not\",\"what'll\":\"what will\",\n",
        "    \"what're\":\"what are\",\"what's\":\"what is\",\"what've\":\"what have\",\"where's\":\"where is\",\"who's\":\"who is\",\n",
        "    \"won't\":\"will not\",\"would've\":\"would have\",\"wouldn't\":\"would not\",\"you'd\":\"you would\",\"you'll\":\"you will\",\"you're\":\"you are\"\n",
        "    }\n",
        "    # Cleaner function\n",
        "    REPLACE_BY_SPACE_RE = re.compile(r'[\\t\\n\\r]+')\n",
        "    BAD_SYMBOLS_RE = re.compile(r'[^0-9a-z ]')\n",
        "\n",
        "    q_decontracted = []\n",
        "    for word in q.split():\n",
        "        if word in contractions:\n",
        "            word = contractions[word]\n",
        "        q_decontracted.append(word)\n",
        "    q = \" \".join(q_decontracted)\n",
        "\n",
        "    # Remove HTML tags\n",
        "    q = BeautifulSoup(q, \"html.parser\").get_text()\n",
        "\n",
        "    # Remove punctuation\n",
        "    q = re.sub(r'\\W', ' ', q).strip()\n",
        "\n",
        "    # replace newlines and tabs with space\n",
        "    q = REPLACE_BY_SPACE_RE.sub(' ', q)\n",
        "    # remove unwanted characters (keep a-z and numbers)\n",
        "    q = BAD_SYMBOLS_RE.sub(' ', q)\n",
        "    # collapse multiple spaces\n",
        "    q = re.sub(' +', ' ', q).strip()\n",
        "\n",
        "    return q\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GsFTAhDgXbdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing\n",
        "df['question1'] = df['question1'].apply(preprocess)\n",
        "df['question2'] = df['question2'].apply(preprocess)"
      ],
      "metadata": {
        "id": "-iBJX9XnXbg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "vZOhsr5NcvnW",
        "outputId": "1fc3d159-8df0-4eb7-f24b-4719ed5ec988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           question1  \\\n",
              "0  what is the step by step guide to invest in sh...   \n",
              "1   what is the story of kohinoor koh i noor diamond   \n",
              "2  how can i increase the speed of my internet co...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  what is the step by step guide to invest in sh...             0  \n",
              "1  what would happen if the indian government sto...             0  \n",
              "2  how can internet speed be increased by hacking...             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f89ff09-e509-4592-ba51-e15db2bdf93b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what is the step by step guide to invest in sh...</td>\n",
              "      <td>what is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is the story of kohinoor koh i noor diamond</td>\n",
              "      <td>what would happen if the indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how can i increase the speed of my internet co...</td>\n",
              "      <td>how can internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f89ff09-e509-4592-ba51-e15db2bdf93b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f89ff09-e509-4592-ba51-e15db2bdf93b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f89ff09-e509-4592-ba51-e15db2bdf93b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4d078fd5-ce7f-4a83-a3b8-e9792dc61be1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d078fd5-ce7f-4a83-a3b8-e9792dc61be1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4d078fd5-ce7f-4a83-a3b8-e9792dc61be1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "NYGaE3vR-4fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "MAX_NB_WORDS = 200000\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, oov_token='__OOV__')\n",
        "tokenizer.fit_on_texts(pd.concat([df['question1'], df['question2']]))\n",
        "# --- Save tokenizer for later use ---\n",
        "import pickle\n",
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "q1_sequences = tokenizer.texts_to_sequences(df['question1'])\n",
        "q2_sequences = tokenizer.texts_to_sequences(df['question2'])"
      ],
      "metadata": {
        "id": "Z2AUbFOfXbky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate lengths of all question sequences (q1 + q2)\n",
        "lengths = [len(seq) for seq in q1_sequences + q2_sequences]\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Show the 95th percentile length\n",
        "print(\"95th percentile:\", np.percentile(lengths, 95))\n",
        "\n",
        "# Show the maximum sequence length\n",
        "print(\"Max length:\", max(lengths))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyGr8hg9XboT",
        "outputId": "0fb0d921-7b9a-49fa-eafd-7bf6d19a1cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95th percentile: 23.0\n",
            "Max length: 247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find maximum length and pad sequences\n",
        "import gc\n",
        "\n",
        "# calculate max length\n",
        "max_len = 30\n",
        "\n",
        "q1_padded = pad_sequences(q1_sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "q2_padded = pad_sequences(q2_sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "# Labels\n",
        "labels = df['is_duplicate'].values\n",
        "\n",
        "print(\"Q1 shape:\", q1_padded.shape)\n",
        "print(\"Q2 shape:\", q2_padded.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "# Free memory\n",
        "_del = [q1_sequences, q2_sequences]\n",
        "_del = None\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b8rnWhdXwYF",
        "outputId": "5aa7dab5-8160-41d2-d4c5-5f486d170e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 shape: (404287, 30)\n",
            "Q2 shape: (404287, 30)\n",
            "Labels shape: (404287,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Hyperparameters & Seed\n",
        "# ===============================\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "LSTM_UNITS = 256\n",
        "DROPOUT_RATE = 0.2\n",
        "EMB_TRAINABLE = False\n",
        "BATCH_SIZE = 512\n",
        "EPOCHS = 20\n",
        "EMBEDDING_DIM = 100\n",
        "vocab_size = min(200000, len(tokenizer.word_index)+1)\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Load GloVe embeddings & build embedding matrix\n",
        "# ===============================\n",
        "import os\n",
        "GLOVE_DIR = \"./glove\"  # adjust path if needed\n",
        "os.makedirs(GLOVE_DIR, exist_ok=True)\n",
        "\n",
        "glove_path = os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')\n",
        "if not os.path.exists(glove_path):\n",
        "    print('Downloading GloVe embeddings...')\n",
        "    !wget -q http://nlp.stanford.edu/data/glove.6B.zip -P {GLOVE_DIR}\n",
        "    !unzip -o {os.path.join(GLOVE_DIR,\"glove.6B.zip\")} -d {GLOVE_DIR}\n",
        "else:\n",
        "    print('GloVe already present')\n",
        "\n",
        "# Build embedding index\n",
        "emb_index = {}\n",
        "with open(glove_path, 'r', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        emb_index[word] = coefs\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= vocab_size:\n",
        "        continue\n",
        "    vec = emb_index.get(word)\n",
        "    if vec is not None:\n",
        "        embedding_matrix[i] = vec\n",
        "\n",
        "emb_index = None  # free memory\n",
        "print('Embedding matrix shape:', embedding_matrix.shape)\n",
        "\n",
        "# ===============================\n",
        "# Train/validation split\n",
        "# ===============================\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_q1_train, X_q1_val, X_q2_train, X_q2_val, y_train, y_val = train_test_split(\n",
        "    q1_padded, q2_padded, labels, test_size=0.1, random_state=SEED, stratify=labels\n",
        ")\n",
        "print('Train size:', len(y_train), 'Val size:', len(y_val))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEcYwnCbXwid",
        "outputId": "1e3b41b9-de13-4f26-9e65-cc1a91021644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading GloVe embeddings...\n",
            "Archive:  ./glove/glove.6B.zip\n",
            "  inflating: ./glove/glove.6B.50d.txt  \n",
            "  inflating: ./glove/glove.6B.100d.txt  \n",
            "  inflating: ./glove/glove.6B.200d.txt  \n",
            "  inflating: ./glove/glove.6B.300d.txt  \n",
            "Embedding matrix shape: (85876, 100)\n",
            "Train size: 363858 Val size: 40429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model architecture with GloVe embeddings"
      ],
      "metadata": {
        "id": "yv1UBc3s_HgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture with GloVe embeddings\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, BatchNormalization, Lambda, concatenate,Subtract, Multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "q1_in = Input(shape=(max_len,))\n",
        "q2_in = Input(shape=(max_len,))\n",
        "\n",
        "# Embedding layer (shared)\n",
        "embedding_layer = Embedding(input_dim=vocab_size,\n",
        "                            output_dim=EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_len,\n",
        "                            trainable=EMB_TRAINABLE,\n",
        "                            name='embedding')\n",
        "\n",
        "# Shared encoder (BiLSTM)\n",
        "shared_lstm = Bidirectional(LSTM(LSTM_UNITS, return_sequences=False, dropout=DROPOUT_RATE, recurrent_dropout=DROPOUT_RATE))\n",
        "\n",
        "\n",
        "# Encode both inputs\n",
        "q1_emb = embedding_layer(q1_in)\n",
        "q2_emb = embedding_layer(q2_in)\n",
        "\n",
        "q1_vec = shared_lstm(q1_emb)\n",
        "q2_vec = shared_lstm(q2_emb)\n",
        "\n",
        "# Combine features: absolute difference, element-wise multiply, and concat original vectors\n",
        "class AbsLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.abs(inputs)\n",
        "\n",
        "diff = Subtract()([q1_vec, q2_vec])\n",
        "abs_diff = AbsLayer()(diff)\n",
        "\n",
        "\n",
        "mul = Multiply()([q1_vec,q2_vec])\n",
        "merged = concatenate([q1_vec,q2_vec,abs_diff,mul])\n",
        "\n",
        "# Dense layers for classification\n",
        "x = BatchNormalization()(merged)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(DROPOUT_RATE)(x)\n",
        "out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=[q1_in, q2_in], outputs=out)\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-3), metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# ===============================\n",
        "# Callbacks & Class Weights\n",
        "# ===============================\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "checkpoint_path = 'siamese_bilstm_best.h5'\n",
        "callbacks = [\n",
        "    ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1,mode='min'),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True,mode='min'),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6, verbose=1)\n",
        "]\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = {i: w for i,w in enumerate(class_weights)}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "IHojH_ZjXwlt",
        "outputId": "17eb446f-c15e-4362-c063-a92f5dfebc75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │  \u001b[38;5;34m8,587,600\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m731,136\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ subtract (\u001b[38;5;33mSubtract\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ abs_layer           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ subtract[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mAbsLayer\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ abs_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │      \u001b[38;5;34m8,192\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m524,544\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,587,600</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">731,136</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ subtract (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ abs_layer           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ subtract[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AbsLayer</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ abs_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,884,497\u001b[0m (37.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,884,497</span> (37.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,292,801\u001b[0m (4.93 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,292,801</span> (4.93 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,591,696\u001b[0m (32.77 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,591,696</span> (32.77 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "n-mJW4Zu_M1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "\n",
        "history = model.fit(\n",
        "    [X_q1_train,X_q2_train], y_train,\n",
        "    validation_data=([X_q1_val,X_q2_val], y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# Save final model\n",
        "# ===============================\n",
        "model.save('siamese_bilstm_final.keras')\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1E2kYntXwpQ",
        "outputId": "eb9c103a-ee1b-4e74-ba30-bf98b52d872b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.6668 - loss: 0.5913\n",
            "Epoch 1: val_loss improved from inf to 0.62532, saving model to siamese_bilstm_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 335ms/step - accuracy: 0.6669 - loss: 0.5912 - val_accuracy: 0.6515 - val_loss: 0.6253 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.7571 - loss: 0.4723\n",
            "Epoch 2: val_loss improved from 0.62532 to 0.53487, saving model to siamese_bilstm_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 331ms/step - accuracy: 0.7571 - loss: 0.4723 - val_accuracy: 0.7215 - val_loss: 0.5349 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.7780 - loss: 0.4389\n",
            "Epoch 3: val_loss did not improve from 0.53487\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 332ms/step - accuracy: 0.7780 - loss: 0.4389 - val_accuracy: 0.7325 - val_loss: 0.5539 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.7919 - loss: 0.4154\n",
            "Epoch 4: val_loss did not improve from 0.53487\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 331ms/step - accuracy: 0.7919 - loss: 0.4154 - val_accuracy: 0.7371 - val_loss: 0.5435 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.8029 - loss: 0.3975\n",
            "Epoch 5: val_loss improved from 0.53487 to 0.53403, saving model to siamese_bilstm_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 335ms/step - accuracy: 0.8029 - loss: 0.3975 - val_accuracy: 0.7406 - val_loss: 0.5340 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.8115 - loss: 0.3824\n",
            "Epoch 6: val_loss improved from 0.53403 to 0.48469, saving model to siamese_bilstm_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 334ms/step - accuracy: 0.8115 - loss: 0.3824 - val_accuracy: 0.7679 - val_loss: 0.4847 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.8188 - loss: 0.3693\n",
            "Epoch 7: val_loss did not improve from 0.48469\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 332ms/step - accuracy: 0.8188 - loss: 0.3693 - val_accuracy: 0.7648 - val_loss: 0.4930 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.8249 - loss: 0.3573\n",
            "Epoch 8: val_loss did not improve from 0.48469\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 330ms/step - accuracy: 0.8249 - loss: 0.3573 - val_accuracy: 0.7700 - val_loss: 0.4955 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.8295 - loss: 0.3478\n",
            "Epoch 9: val_loss did not improve from 0.48469\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 339ms/step - accuracy: 0.8295 - loss: 0.3478 - val_accuracy: 0.7729 - val_loss: 0.4864 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.8360 - loss: 0.3387\n",
            "Epoch 10: val_loss improved from 0.48469 to 0.48327, saving model to siamese_bilstm_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 345ms/step - accuracy: 0.8360 - loss: 0.3387 - val_accuracy: 0.7740 - val_loss: 0.4833 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.8412 - loss: 0.3278\n",
            "Epoch 11: val_loss improved from 0.48327 to 0.46911, saving model to siamese_bilstm_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 333ms/step - accuracy: 0.8412 - loss: 0.3278 - val_accuracy: 0.7826 - val_loss: 0.4691 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.8456 - loss: 0.3206\n",
            "Epoch 12: val_loss improved from 0.46911 to 0.44948, saving model to siamese_bilstm_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 337ms/step - accuracy: 0.8456 - loss: 0.3206 - val_accuracy: 0.7872 - val_loss: 0.4495 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.8492 - loss: 0.3132\n",
            "Epoch 13: val_loss did not improve from 0.44948\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 337ms/step - accuracy: 0.8492 - loss: 0.3132 - val_accuracy: 0.7915 - val_loss: 0.4685 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.8524 - loss: 0.3075\n",
            "Epoch 14: val_loss improved from 0.44948 to 0.42874, saving model to siamese_bilstm_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 334ms/step - accuracy: 0.8524 - loss: 0.3075 - val_accuracy: 0.8035 - val_loss: 0.4287 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.8572 - loss: 0.2984\n",
            "Epoch 15: val_loss did not improve from 0.42874\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 337ms/step - accuracy: 0.8572 - loss: 0.2984 - val_accuracy: 0.7983 - val_loss: 0.4476 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.8599 - loss: 0.2928\n",
            "Epoch 16: val_loss did not improve from 0.42874\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 342ms/step - accuracy: 0.8599 - loss: 0.2928 - val_accuracy: 0.7935 - val_loss: 0.4602 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.8628 - loss: 0.2891\n",
            "Epoch 17: val_loss did not improve from 0.42874\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 335ms/step - accuracy: 0.8628 - loss: 0.2891 - val_accuracy: 0.7972 - val_loss: 0.4572 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.8658 - loss: 0.2827\n",
            "Epoch 18: val_loss did not improve from 0.42874\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 336ms/step - accuracy: 0.8658 - loss: 0.2827 - val_accuracy: 0.8032 - val_loss: 0.4482 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.8721 - loss: 0.2711\n",
            "Epoch 19: val_loss did not improve from 0.42874\n",
            "\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 332ms/step - accuracy: 0.8721 - loss: 0.2711 - val_accuracy: 0.8112 - val_loss: 0.4312 - learning_rate: 5.0000e-04\n",
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "g2J8ReKo_RKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on validation set\n",
        "val_preds = model.predict([X_q1_val, X_q2_val], batch_size=1024)\n",
        "val_preds_label = (val_preds.flatten() >= 0.5).astype(int)\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_val, val_preds_label))\n",
        "print('F1:', f1_score(y_val, val_preds_label))\n",
        "print('Precision:', precision_score(y_val, val_preds_label))\n",
        "print('Recall:', recall_score(y_val, val_preds_label))\n",
        "print('\\nClassification report:\\n', classification_report(y_val, val_preds_label))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGffvYGtecld",
        "outputId": "2ad2e214-eb7d-488a-ac94-60cea6d1759c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 105ms/step\n",
            "Accuracy: 0.8035321180340844\n",
            "F1: 0.7789989148882891\n",
            "Precision: 0.666143231025458\n",
            "Recall: 0.9378936084684443\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.72      0.82     25503\n",
            "           1       0.67      0.94      0.78     14926\n",
            "\n",
            "    accuracy                           0.80     40429\n",
            "   macro avg       0.81      0.83      0.80     40429\n",
            "weighted avg       0.85      0.80      0.81     40429\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Duplicate Question Pair Prediction"
      ],
      "metadata": {
        "id": "HiAK7eL9_pgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_single(q):\n",
        "    q = preprocess(q)\n",
        "    seq = tokenizer.texts_to_sequences([q])\n",
        "    pad = pad_sequences(seq, maxlen=30, padding='post')\n",
        "    return pad\n",
        "\n",
        "def predict_pair(q1,q2,thresh=0.5):\n",
        "    s1 = preprocess_single(q1)\n",
        "    s2 = preprocess_single(q2)\n",
        "    p = model.predict([s1,s2])[0,0]\n",
        "    return {'probability': float(p), 'is_duplicate': int(p>=thresh)}\n",
        "\n",
        "# Test examples\n",
        "examples = [\n",
        "    (\"What is the capital of France?\", \"Which city is the capital of France?\"),\n",
        "    (\"How to lose weight fast?\", \"What is the best way to lose weight in 2 weeks?\"),\n",
        "    (\"Who is the president of the USA?\", \"Name the current US president\"),\n",
        "    (\"What is AI?\", \"Explain artificial intelligence\"),\n",
        "    (\"How can I cook pasta?\", \"What are some tips to make spaghetti?\"),\n",
        "    (\"Best programming language for beginners?\", \"Which language should a new programmer learn first?\"),\n",
        "    (\"Where is Mount Everest located?\", \"Which country has Mount Everest?\"),\n",
        "    (\"What is the time in London?\", \"Tell me the population of London\"),\n",
        "    (\"Can I lose weight without exercise?\", \"Is it possible to reduce weight by only dieting?\"),\n",
        "    (\"Who won the FIFA World Cup in 2018?\",\"Which country was the winner of FIFA 2018?\"),\n",
        "    (\"Who is the founder of Microsoft?\",\"Who started Microsoft company?\"),\n",
        "    (\"What is the idea behind democracy?\",\"What is the core idea of democracy?\"),\n",
        "    (\"What is the idea behind democracy?\",\"What is the core idea of sociology?\")\n",
        "]\n",
        "\n",
        "for a,b in examples:\n",
        "    print(a,\"||\",b,\"->\", predict_pair(a,b))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G027U0pwf0-",
        "outputId": "59e14c17-1694-4354-edbe-ddd760b9203f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "What is the capital of France? || Which city is the capital of France? -> {'probability': 0.9271326065063477, 'is_duplicate': 1}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "How to lose weight fast? || What is the best way to lose weight in 2 weeks? -> {'probability': 0.8783103823661804, 'is_duplicate': 1}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
            "Who is the president of the USA? || Name the current US president -> {'probability': 0.9656570553779602, 'is_duplicate': 1}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step\n",
            "What is AI? || Explain artificial intelligence -> {'probability': 0.010477392934262753, 'is_duplicate': 0}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
            "How can I cook pasta? || What are some tips to make spaghetti? -> {'probability': 0.26347556710243225, 'is_duplicate': 0}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "Best programming language for beginners? || Which language should a new programmer learn first? -> {'probability': 0.8590215444564819, 'is_duplicate': 1}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "Where is Mount Everest located? || Which country has Mount Everest? -> {'probability': 0.7621631026268005, 'is_duplicate': 1}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
            "What is the time in London? || Tell me the population of London -> {'probability': 0.798858642578125, 'is_duplicate': 1}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "Can I lose weight without exercise? || Is it possible to reduce weight by only dieting? -> {'probability': 0.9396628737449646, 'is_duplicate': 1}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "Who won the FIFA World Cup in 2018? || Which country was the winner of FIFA 2018? -> {'probability': 0.9905927777290344, 'is_duplicate': 1}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
            "Who is the founder of Microsoft? || Who started Microsoft company? -> {'probability': 0.8921114802360535, 'is_duplicate': 1}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
            "What is the idea behind democracy? || What is the core idea of democracy? -> {'probability': 0.9666857719421387, 'is_duplicate': 1}\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
            "What is the idea behind democracy? || What is the core idea of sociology? -> {'probability': 0.022017264738678932, 'is_duplicate': 0}\n"
          ]
        }
      ]
    }
  ]
}