{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13196284,"sourceType":"datasetVersion","datasetId":8362911}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Required Libraries","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# Basic imports\nimport random\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n\n# TensorFlow / Keras imports\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, BatchNormalization, Lambda, concatenate, Multiply\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\nprint(\"TensorFlow version:\", tf.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T16:10:06.121840Z","iopub.execute_input":"2025-09-29T16:10:06.122102Z","iopub.status.idle":"2025-09-29T16:10:26.728120Z","shell.execute_reply.started":"2025-09-29T16:10:06.122083Z","shell.execute_reply":"2025-09-29T16:10:26.727417Z"}},"outputs":[{"name":"stderr","text":"2025-09-29 16:10:10.193048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759162210.567208      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759162210.674116      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"TensorFlow version: 2.18.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv(\"/kaggle/input/quora-question-pairs-dataset/train.csv\")\n\n# select columns first\ndf = df[['question1', 'question2', 'is_duplicate']]\n\n# then drop missing values (inplace)\ndf.dropna(inplace=True)\n\n# convert label to int\ndf['is_duplicate'] = df['is_duplicate'].astype(int)\n\nprint(\"Dataset shape:\", df.shape)\nprint(df['is_duplicate'].value_counts(normalize=True))\nprint(df.head(3).to_dict(orient='records'))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T16:10:26.729148Z","iopub.execute_input":"2025-09-29T16:10:26.729667Z","iopub.status.idle":"2025-09-29T16:10:28.661291Z","shell.execute_reply.started":"2025-09-29T16:10:26.729648Z","shell.execute_reply":"2025-09-29T16:10:28.660591Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: (404287, 3)\nis_duplicate\n0    0.630799\n1    0.369201\nName: proportion, dtype: float64\n[{'question1': 'What is the step by step guide to invest in share market in india?', 'question2': 'What is the step by step guide to invest in share market?', 'is_duplicate': 0}, {'question1': 'What is the story of Kohinoor (Koh-i-Noor) Diamond?', 'question2': 'What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?', 'is_duplicate': 0}, {'question1': 'How can I increase the speed of my internet connection while using a VPN?', 'question2': 'How can Internet speed be increased by hacking through DNS?', 'is_duplicate': 0}]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"import re\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\ndef preprocess(q):\n    q = str(q).lower().strip()\n    \n    # Replace special characters\n    q = q.replace('%','percent').replace('$','dollar').replace('@','at').replace('₹','rupee').replace('€','euro')\n    \n    # Remove math token\n    q = q.replace('[math]','')\n    \n    # Numbers to k/m/b\n    q = q.replace(',000,000,000','b').replace(',000,000','m').replace(',000','k')\n    q = re.sub(r'([0-9]+)000000000',r'\\1b',q)\n    q = re.sub(r'([0-9]+)000000',r'\\1m',q)\n    q = re.sub(r'([0-9]+)000',r'\\1k',q)\n    \n    # Contractions\n    contractions = { \n       \"ain't\":\"is not\",\"aren't\":\"are not\",\"can't\":\"cannot\",\"can't've\":\"cannot have\",\"cause\":\"because\",\n    \"could've\":\"could have\",\"couldn't\":\"could not\",\"didn't\":\"did not\",\"doesn't\":\"does not\",\"don't\":\"do not\",\n    \"hadn't\":\"had not\",\"hasn't\":\"has not\",\"haven't\":\"have not\",\"he'd\":\"he would\",\"he'll\":\"he will\",\n    \"he's\":\"he is\",\"how'd\":\"how did\",\"how'll\":\"how will\",\"how's\":\"how is\",\"i'd\":\"i would\",\"i'll\":\"i will\",\n    \"i'm\":\"i am\",\"isn't\":\"is not\",\"it'd\":\"it would\",\"it'll\":\"it will\",\"it's\":\"it is\",\"let's\":\"let us\",\n    \"ma'am\":\"madam\",\"mightn't\":\"might not\",\"mustn't\":\"must not\",\"shan't\":\"shall not\",\"she'd\":\"she would\",\n    \"she'll\":\"she will\",\"she's\":\"she is\",\"should've\":\"should have\",\"shouldn't\":\"should not\",\"that's\":\"that is\",\n    \"there's\":\"there is\",\"they'd\":\"they would\",\"they'll\":\"they will\",\"they're\":\"they are\",\"they've\":\"they have\",\n    \"wasn't\":\"was not\",\"we'd\":\"we would\",\"we're\":\"we are\",\"we've\":\"we have\",\"weren't\":\"were not\",\"what'll\":\"what will\",\n    \"what're\":\"what are\",\"what's\":\"what is\",\"what've\":\"what have\",\"where's\":\"where is\",\"who's\":\"who is\",\n    \"won't\":\"will not\",\"would've\":\"would have\",\"wouldn't\":\"would not\",\"you'd\":\"you would\",\"you'll\":\"you will\",\"you're\":\"you are\"\n    }\n    # Cleaner function\n    REPLACE_BY_SPACE_RE = re.compile(r'[\\t\\n\\r]+')\n    BAD_SYMBOLS_RE = re.compile(r'[^0-9a-z ]')\n    \n    q_decontracted = []\n    for word in q.split():\n        if word in contractions:\n            word = contractions[word]\n        q_decontracted.append(word)\n    q = \" \".join(q_decontracted)\n    \n    # Remove HTML tags\n    q = BeautifulSoup(q, \"html.parser\").get_text()\n    \n    # Remove punctuation\n    q = re.sub(r'\\W', ' ', q).strip()\n\n    # replace newlines and tabs with space\n    q = REPLACE_BY_SPACE_RE.sub(' ', q)\n    # remove unwanted characters (keep a-z and numbers)\n    q = BAD_SYMBOLS_RE.sub(' ', q)\n    # collapse multiple spaces\n    q = re.sub(' +', ' ', q).strip()\n    \n    return q\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T16:10:28.662092Z","iopub.execute_input":"2025-09-29T16:10:28.662316Z","iopub.status.idle":"2025-09-29T16:10:28.995648Z","shell.execute_reply.started":"2025-09-29T16:10:28.662299Z","shell.execute_reply":"2025-09-29T16:10:28.994772Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Apply preprocessing\ndf['question1'] = df['question1'].apply(preprocess)\ndf['question2'] = df['question2'].apply(preprocess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T16:10:28.997063Z","iopub.execute_input":"2025-09-29T16:10:28.997610Z","iopub.status.idle":"2025-09-29T16:11:22.083126Z","shell.execute_reply.started":"2025-09-29T16:10:28.997589Z","shell.execute_reply":"2025-09-29T16:11:22.082513Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T16:11:22.083833Z","iopub.execute_input":"2025-09-29T16:11:22.084020Z","iopub.status.idle":"2025-09-29T16:11:22.103057Z","shell.execute_reply.started":"2025-09-29T16:11:22.084005Z","shell.execute_reply":"2025-09-29T16:11:22.102429Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                           question1  \\\n0  what is the step by step guide to invest in sh...   \n1   what is the story of kohinoor koh i noor diamond   \n2  how can i increase the speed of my internet co...   \n\n                                           question2  is_duplicate  \n0  what is the step by step guide to invest in sh...             0  \n1  what would happen if the indian government sto...             0  \n2  how can internet speed be increased by hacking...             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what is the step by step guide to invest in sh...</td>\n      <td>what is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>what is the story of kohinoor koh i noor diamond</td>\n      <td>what would happen if the indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>how can i increase the speed of my internet co...</td>\n      <td>how can internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"# Tokenization\nMAX_NB_WORDS = 200000\ntokenizer = Tokenizer(num_words=MAX_NB_WORDS, oov_token='__OOV__')\ntokenizer.fit_on_texts(pd.concat([df['question1'], df['question2']]))\n# --- Save tokenizer for later use ---\nimport pickle\nwith open('tokenizer.pkl', 'wb') as f:\n    pickle.dump(tokenizer, f)\n\nq1_sequences = tokenizer.texts_to_sequences(df['question1'])\nq2_sequences = tokenizer.texts_to_sequences(df['question2'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T16:11:22.104693Z","iopub.execute_input":"2025-09-29T16:11:22.104905Z","iopub.status.idle":"2025-09-29T16:11:40.230667Z","shell.execute_reply.started":"2025-09-29T16:11:22.104888Z","shell.execute_reply":"2025-09-29T16:11:40.229990Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Find maximum length and pad sequences\nimport gc\n\n# calculate max length\nmax_len = max(max(map(len, q1_sequences)), max(map(len, q2_sequences)))\n\nq1_padded = pad_sequences(q1_sequences, maxlen=max_len, padding='post', truncating='post')\nq2_padded = pad_sequences(q2_sequences, maxlen=max_len, padding='post', truncating='post')\n\n# Labels\nlabels = df['is_duplicate'].values\n\nprint(\"Q1 shape:\", q1_padded.shape)\nprint(\"Q2 shape:\", q2_padded.shape)\nprint(\"Labels shape:\", labels.shape)\n\n# Free memory\n_del = [q1_sequences, q2_sequences]\n_del = None\ngc.collect()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T16:19:15.101908Z","iopub.execute_input":"2025-09-29T16:19:15.102248Z","iopub.status.idle":"2025-09-29T16:19:17.588136Z","shell.execute_reply.started":"2025-09-29T16:19:15.102227Z","shell.execute_reply":"2025-09-29T16:19:17.587307Z"}},"outputs":[{"name":"stdout","text":"Q1 shape: (404287, 247)\nQ2 shape: (404287, 247)\nLabels shape: (404287,)\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===============================\n# Hyperparameters & Seed\n# ===============================\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\nLSTM_UNITS = 256\nDROPOUT_RATE = 0.2\nEMB_TRAINABLE = False\nBATCH_SIZE = 512\nEPOCHS = 20\nEMBEDDING_DIM = 100\nvocab_size = min(200000, len(tokenizer.word_index)+1)\n\n\n# ===============================\n# Load GloVe embeddings & build embedding matrix\n# ===============================\nimport os\nGLOVE_DIR = \"./glove\"  # adjust path if needed\nos.makedirs(GLOVE_DIR, exist_ok=True)\n\nglove_path = os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')\nif not os.path.exists(glove_path):\n    print('Downloading GloVe embeddings...')\n    !wget -q http://nlp.stanford.edu/data/glove.6B.zip -P {GLOVE_DIR}\n    !unzip -o {os.path.join(GLOVE_DIR,\"glove.6B.zip\")} -d {GLOVE_DIR}\nelse:\n    print('GloVe already present')\n    \n# Build embedding index\nemb_index = {}\nwith open(glove_path, 'r', encoding='utf8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        emb_index[word] = coefs\n\nembedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\nfor word, i in tokenizer.word_index.items():\n    if i >= vocab_size:\n        continue\n    vec = emb_index.get(word)\n    if vec is not None:\n        embedding_matrix[i] = vec\n        \nemb_index = None  # free memory\nprint('Embedding matrix shape:', embedding_matrix.shape)\n\n# ===============================\n# Train/validation split\n# ===============================\nfrom sklearn.model_selection import train_test_split\n\nX_q1_train, X_q1_val, X_q2_train, X_q2_val, y_train, y_val = train_test_split(\n    q1_padded, q2_padded, labels, test_size=0.1, random_state=SEED, stratify=labels\n)\nprint('Train size:', len(y_train), 'Val size:', len(y_val))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:25:45.614607Z","iopub.execute_input":"2025-09-29T08:25:45.614826Z","iopub.status.idle":"2025-09-29T08:28:55.114045Z","shell.execute_reply.started":"2025-09-29T08:25:45.614805Z","shell.execute_reply":"2025-09-29T08:28:55.112839Z"}},"outputs":[{"name":"stdout","text":"Downloading GloVe embeddings...\nArchive:  ./glove/glove.6B.zip\n  inflating: ./glove/glove.6B.50d.txt  \n  inflating: ./glove/glove.6B.100d.txt  \n  inflating: ./glove/glove.6B.200d.txt  \n  inflating: ./glove/glove.6B.300d.txt  \nEmbedding matrix shape: (85876, 100)\nTrain size: 363858 Val size: 40429\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Model architecture with GloVe embeddings","metadata":{}},{"cell_type":"code","source":"# Model architecture with GloVe embeddings\nfrom tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, BatchNormalization, Lambda, concatenate, Multiply\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\n\nq1_in = Input(shape=(max_len,))\nq2_in = Input(shape=(max_len,))\n\n# Embedding layer (shared)\nembedding_layer = Embedding(input_dim=vocab_size,\n                            output_dim=EMBEDDING_DIM,\n                            weights=[embedding_matrix],\n                            input_length=max_len,\n                            trainable=EMB_TRAINABLE,\n                            name='embedding')\n\n# Shared encoder (BiLSTM)\nshared_lstm = Bidirectional(LSTM(LSTM_UNITS, return_sequences=False, dropout=DROPOUT_RATE, recurrent_dropout=DROPOUT_RATE))\n\n\n# Encode both inputs\nq1_emb = embedding_layer(q1_in)\nq2_emb = embedding_layer(q2_in)\n\nq1_vec = shared_lstm(q1_emb)\nq2_vec = shared_lstm(q2_emb)\n\n# Combine features: absolute difference, element-wise multiply, and concat original vectors\nabs_diff = Lambda(lambda x: K.abs(x[0]-x[1]))([q1_vec,q2_vec])\nmul = Multiply()([q1_vec,q2_vec])\nmerged = concatenate([q1_vec,q2_vec,abs_diff,mul])\n\n# Dense layers for classification\nx = BatchNormalization()(merged)\nx = Dense(256, activation='relu')(x)\nx = Dropout(DROPOUT_RATE)(x)\nx = Dense(128, activation='relu')(x)\nx = Dropout(DROPOUT_RATE)(x)\nout = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=[q1_in, q2_in], outputs=out)\nmodel.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-3), metrics=['accuracy'])\nmodel.summary()\n\n# ===============================\n# Callbacks & Class Weights\n# ===============================\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom sklearn.utils import class_weight\n\ncheckpoint_path = 'siamese_bilstm_best.h5'\ncallbacks = [\n    ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1,mode='min'),\n    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True,mode='min'),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n]\n\nclass_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weights = {i: w for i,w in enumerate(class_weights)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:28:55.115440Z","iopub.execute_input":"2025-09-29T08:28:55.115752Z","iopub.status.idle":"2025-09-29T08:28:59.158595Z","shell.execute_reply.started":"2025-09-29T08:28:55.115716Z","shell.execute_reply":"2025-09-29T08:28:59.157833Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\nI0000 00:00:1759134537.050055      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1759134537.050727      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m247\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m247\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m247\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │  \u001b[38;5;34m8,587,600\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m731,136\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ bidirectional[\u001b[38;5;34m1\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ bidirectional[\u001b[38;5;34m1\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional[\u001b[38;5;34m1\u001b[0m]… │\n│                     │                   │            │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                     │                   │            │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │      \u001b[38;5;34m8,192\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m524,544\u001b[0m │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">247</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">247</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">247</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,587,600</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">731,136</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n│                     │                   │            │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                     │                   │            │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,884,497\u001b[0m (37.71 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,884,497</span> (37.71 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,292,801\u001b[0m (4.93 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,292,801</span> (4.93 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,591,696\u001b[0m (32.77 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,591,696</span> (32.77 MB)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"# Train model\n\nhistory = model.fit(\n    [X_q1_train,X_q2_train], y_train,\n    validation_data=([X_q1_val,X_q2_val], y_val),\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    callbacks=callbacks,\n    class_weight=class_weights,\n    verbose=1\n)\n\n# ===============================\n# Save final model\n# ===============================\nmodel.save('siamese_bilstm_final.keras')\nprint(\"Model saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T12:06:26.943968Z","iopub.execute_input":"2025-09-29T12:06:26.944246Z","iopub.status.idle":"2025-09-29T15:07:03.502262Z","shell.execute_reply.started":"2025-09-29T12:06:26.944225Z","shell.execute_reply":"2025-09-29T15:07:03.501540Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8460 - loss: 0.3219\nEpoch 1: val_loss did not improve from 0.43308\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1207s\u001b[0m 2s/step - accuracy: 0.8460 - loss: 0.3219 - val_accuracy: 0.7819 - val_loss: 0.4504 - learning_rate: 0.0010\nEpoch 2/20\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8488 - loss: 0.3143\nEpoch 2: val_loss did not improve from 0.43308\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1206s\u001b[0m 2s/step - accuracy: 0.8488 - loss: 0.3143 - val_accuracy: 0.7918 - val_loss: 0.4410 - learning_rate: 0.0010\nEpoch 3/20\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8531 - loss: 0.3072\nEpoch 3: val_loss did not improve from 0.43308\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1204s\u001b[0m 2s/step - accuracy: 0.8531 - loss: 0.3072 - val_accuracy: 0.7941 - val_loss: 0.4349 - learning_rate: 0.0010\nEpoch 4/20\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8567 - loss: 0.3031\nEpoch 4: val_loss improved from 0.43308 to 0.42195, saving model to siamese_bilstm_best.h5\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1206s\u001b[0m 2s/step - accuracy: 0.8567 - loss: 0.3031 - val_accuracy: 0.8029 - val_loss: 0.4219 - learning_rate: 0.0010\nEpoch 5/20\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8587 - loss: 0.2974\nEpoch 5: val_loss improved from 0.42195 to 0.41999, saving model to siamese_bilstm_best.h5\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1202s\u001b[0m 2s/step - accuracy: 0.8587 - loss: 0.2974 - val_accuracy: 0.8043 - val_loss: 0.4200 - learning_rate: 0.0010\nEpoch 6/20\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8632 - loss: 0.2909\nEpoch 6: val_loss did not improve from 0.41999\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1203s\u001b[0m 2s/step - accuracy: 0.8632 - loss: 0.2909 - val_accuracy: 0.7953 - val_loss: 0.4610 - learning_rate: 0.0010\nEpoch 7/20\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8640 - loss: 0.2870\nEpoch 7: val_loss did not improve from 0.41999\n\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1203s\u001b[0m 2s/step - accuracy: 0.8640 - loss: 0.2870 - val_accuracy: 0.7955 - val_loss: 0.4496 - learning_rate: 0.0010\nEpoch 8/20\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8709 - loss: 0.2753\nEpoch 8: val_loss did not improve from 0.41999\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1203s\u001b[0m 2s/step - accuracy: 0.8709 - loss: 0.2753 - val_accuracy: 0.8103 - val_loss: 0.4260 - learning_rate: 5.0000e-04\nEpoch 9/20\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8753 - loss: 0.2666\nEpoch 9: val_loss did not improve from 0.41999\n\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m711/711\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1202s\u001b[0m 2s/step - accuracy: 0.8753 - loss: 0.2666 - val_accuracy: 0.8104 - val_loss: 0.4333 - learning_rate: 5.0000e-04\nModel saved successfully!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Evaluate Model","metadata":{}},{"cell_type":"code","source":"# Evaluation on validation set \nval_preds = model.predict([X_q1_val, X_q2_val], batch_size=1024)\nval_preds_label = (val_preds.flatten() >= 0.5).astype(int)\n\nprint('Accuracy:', accuracy_score(y_val, val_preds_label))\nprint('F1:', f1_score(y_val, val_preds_label))\nprint('Precision:', precision_score(y_val, val_preds_label))\nprint('Recall:', recall_score(y_val, val_preds_label))\nprint('\\nClassification report:\\n', classification_report(y_val, val_preds_label))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T15:22:28.809856Z","iopub.execute_input":"2025-09-29T15:22:28.810475Z","iopub.status.idle":"2025-09-29T15:22:53.271332Z","shell.execute_reply.started":"2025-09-29T15:22:28.810450Z","shell.execute_reply":"2025-09-29T15:22:53.270752Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 555ms/step\nAccuracy: 0.8043483637982636\nF1: 0.779493755575379\nPrecision: 0.667478277475413\nRecall: 0.9366876591183171\n\nClassification report:\n               precision    recall  f1-score   support\n\n           0       0.95      0.73      0.82     25503\n           1       0.67      0.94      0.78     14926\n\n    accuracy                           0.80     40429\n   macro avg       0.81      0.83      0.80     40429\nweighted avg       0.85      0.80      0.81     40429\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef preprocess_single(q):\n    q = preprocess(q)\n    seq = tokenizer.texts_to_sequences([q])\n    pad = pad_sequences(seq, maxlen=247, padding='post')\n    return pad\n\ndef predict_pair(q1,q2,thresh=0.5):\n    s1 = preprocess_single(q1)\n    s2 = preprocess_single(q2)\n    p = model.predict([s1,s2])[0,0]\n    return {'probability': float(p), 'is_duplicate': int(p>=thresh)}\n\n# Test examples\nexamples = [\n    (\"What is the capital of France?\", \"Which city is the capital of France?\"),\n    (\"How to lose weight fast?\", \"What is the best way to lose weight in 2 weeks?\"),\n    (\"Who is the president of the USA?\", \"Name the current US president\"),\n    (\"What is AI?\", \"Explain artificial intelligence\"),\n    (\"How can I cook pasta?\", \"What are some tips to make spaghetti?\"),\n    (\"Best programming language for beginners?\", \"Which language should a new programmer learn first?\"),\n    (\"Where is Mount Everest located?\", \"Which country has Mount Everest?\"),\n    (\"What is the time in London?\", \"Tell me the population of London\"),\n    (\"Can I lose weight without exercise?\", \"Is it possible to reduce weight by only dieting?\"),\n    (\"Who won the FIFA World Cup in 2018?\",\"Which country was the winner of FIFA 2018?\"),\n    (\"Who is the founder of Microsoft?\",\"Who started Microsoft company?\"),\n    (\"What is the idea behind democracy?\",\"What is the core idea of democracy?\"),\n    (\"What is the idea behind democracy?\",\"What is the core idea of sociology?\")\n]\n\nfor a,b in examples:\n    print(a,\"||\",b,\"->\", predict_pair(a,b))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T15:52:39.732378Z","iopub.execute_input":"2025-09-29T15:52:39.733142Z","iopub.status.idle":"2025-09-29T15:52:45.588808Z","shell.execute_reply.started":"2025-09-29T15:52:39.733116Z","shell.execute_reply":"2025-09-29T15:52:45.588234Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step\nWhat is the capital of France? || Which city is the capital of France? -> {'probability': 0.9725468158721924, 'is_duplicate': 1}\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step\nHow to lose weight fast? || What is the best way to lose weight in 2 weeks? -> {'probability': 0.9895206689834595, 'is_duplicate': 1}\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\nWho is the president of the USA? || Name the current US president -> {'probability': 0.2401398867368698, 'is_duplicate': 0}\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\nWhat is AI? || Explain artificial intelligence -> {'probability': 0.0025163504760712385, 'is_duplicate': 0}\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step\nHow can I cook pasta? || What are some tips to make spaghetti? -> {'probability': 0.2488338202238083, 'is_duplicate': 0}\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step\nBest programming language for beginners? || Which language should a new programmer learn first? -> {'probability': 0.9482547640800476, 'is_duplicate': 1}\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step\nWhere is Mount Everest located? || Which country has Mount Everest? -> {'probability': 0.8502293825149536, 'is_duplicate': 1}\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step\nWhat is the time in London? || Tell me the population of London -> {'probability': 0.7484902143478394, 'is_duplicate': 1}\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step\nCan I lose weight without exercise? || Is it possible to reduce weight by only dieting? -> {'probability': 0.912208080291748, 'is_duplicate': 1}\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step\nWho won the FIFA World Cup in 2018? || Which country was the winner of FIFA 2018? -> {'probability': 0.6520803570747375, 'is_duplicate': 1}\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step\nWho is the founder of Microsoft? || Who started Microsoft company? -> {'probability': 0.9475701451301575, 'is_duplicate': 1}\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step\nWhat is the idea behind democracy? || What is the core idea of democracy? -> {'probability': 0.9213481545448303, 'is_duplicate': 1}\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step\nWhat is the idea behind democracy? || What is the core idea of sociology? -> {'probability': 0.017769476398825645, 'is_duplicate': 0}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}